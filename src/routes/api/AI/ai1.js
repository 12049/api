import express from 'express';
import axios from 'axios';

const router = express.Router();

// Ù‚Ø§Ø¦Ù…Ø© Ø®Ø¯Ù…Ø§Øª Ø§Ù„Ø°ÙƒØ§Ø¡ Ø§Ù„Ø§ØµØ·Ù†Ø§Ø¹ÙŠ Ø§Ù„Ù…Ø®ØªÙ„ÙØ©
const aiServices = {
  openai: {
    base: "https://api.openai.com/v1",
    endpoints: {
      chat: "/chat/completions",
      image: "/images/generations",
      moderation: "/moderations"
    }
  },
  google: {
    base: "https://generativelanguage.googleapis.com/v1beta",
    endpoints: {
      chat: "/models/gemini-pro:generateContent"
    }
  },
  huggingface: {
    base: "https://api-inference.huggingface.co/models",
    endpoints: {
      summarization: "/facebook/bart-large-cnn",
      translation: "/Helsinki-NLP/opus-mt-ar-en",
      sentiment: "/distilbert-base-uncased-finetuned-sst-2-english"
    }
  }
};

// Ù‡ÙŠØ¯Ø±Ø§Øª Ø¹Ø§Ù…Ø©
const commonHeaders = {
  'Content-Type': 'application/json',
  'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36'
};

// ÙˆØ¸ÙŠÙØ© Ù„Ù„ØªØ¹Ø§Ù…Ù„ Ù…Ø¹ Ø§Ù„Ø£Ø®Ø·Ø§Ø¡
function handleError(service, error) {
  console.error(`âŒ Ø®Ø·Ø£ ÙÙŠ Ø®Ø¯Ù…Ø© ${service}:`, error.message);
  return {
    status: false,
    message: `Ø­Ø¯Ø« Ø®Ø·Ø£ ÙÙŠ Ø®Ø¯Ù…Ø© ${service}`,
    error: error.message,
    details: error.response?.data || null
  };
}

// ==================== 1. Ø·Ù„Ø¨ ChatGPT/OpenAI ====================
async function chatWithGPT(query, options = {}) {
  if (!query) return { status: false, message: "âš ï¸ ÙŠØ±Ø¬Ù‰ ÙƒØªØ§Ø¨Ø© Ù†Øµ Ù„Ù„Ù…Ø­Ø§Ø¯Ø«Ø©!" };
  
  const apiKey = process.env.OPENAI_API_KEY;
  if (!apiKey) {
    return { 
      status: false, 
      message: "âŒ Ù…ÙØªØ§Ø­ OpenAI ØºÙŠØ± Ù…ÙˆØ¬ÙˆØ¯. Ø§Ø¶Ø¨Ø· OPENAI_API_KEY ÙÙŠ Ø§Ù„Ø¨ÙŠØ¦Ø©." 
    };
  }

  const {
    model = "gpt-3.5-turbo",
    temperature = 0.7,
    max_tokens = 1000
  } = options;

  try {
    const { data } = await axios.post(
      `${aiServices.openai.base}${aiServices.openai.endpoints.chat}`,
      {
        model: model,
        messages: [
          { 
            role: "system", 
            content: "Ø£Ù†Øª Ù…Ø³Ø§Ø¹Ø¯ Ø°ÙƒÙŠ ÙŠØªØ­Ø¯Ø« Ø§Ù„Ø¹Ø±Ø¨ÙŠØ© Ø¨Ø·Ù„Ø§Ù‚Ø©. Ø£Ø¬Ø¨ Ø¨Ø·Ø±ÙŠÙ‚Ø© Ù…ÙÙŠØ¯Ø© ÙˆØ¯Ù‚ÙŠÙ‚Ø©." 
          },
          { role: "user", content: query }
        ],
        temperature: temperature,
        max_tokens: max_tokens
      },
      {
        headers: {
          ...commonHeaders,
          'Authorization': `Bearer ${apiKey}`
        }
      }
    );

    return {
      status: true,
      service: "OpenAI ChatGPT",
      model: data.model,
      response: data.choices[0].message.content,
      usage: {
        prompt_tokens: data.usage.prompt_tokens,
        completion_tokens: data.usage.completion_tokens,
        total_tokens: data.usage.total_tokens
      },
      finish_reason: data.choices[0].finish_reason
    };
  } catch (error) {
    return handleError("OpenAI", error);
  }
}

// ==================== 2. ØªÙˆÙ„ÙŠØ¯ ØµÙˆØ± Ø¨Ù€ DALL-E ====================
async function generateImage(prompt, options = {}) {
  if (!prompt) return { status: false, message: "âš ï¸ ÙŠØ±Ø¬Ù‰ ÙƒØªØ§Ø¨Ø© ÙˆØµÙ Ù„Ù„ØµÙˆØ±Ø©!" };
  
  const apiKey = process.env.OPENAI_API_KEY;
  if (!apiKey) {
    return { 
      status: false, 
      message: "âŒ Ù…ÙØªØ§Ø­ OpenAI ØºÙŠØ± Ù…ÙˆØ¬ÙˆØ¯. Ø§Ø¶Ø¨Ø· OPENAI_API_KEY ÙÙŠ Ø§Ù„Ø¨ÙŠØ¦Ø©." 
    };
  }

  const {
    size = "1024x1024",
    quality = "standard",
    n = 1
  } = options;

  try {
    const { data } = await axios.post(
      `${aiServices.openai.base}${aiServices.openai.endpoints.image}`,
      {
        prompt: prompt,
        n: parseInt(n),
        size: size,
        quality: quality
      },
      {
        headers: {
          ...commonHeaders,
          'Authorization': `Bearer ${apiKey}`
        }
      }
    );

    return {
      status: true,
      service: "OpenAI DALL-E",
      images: data.data.map((img, index) => ({
        id: `img_${Date.now()}_${index}`,
        url: img.url,
        prompt: prompt,
        revised_prompt: img.revised_prompt || prompt
      })),
      size: size,
      quality: quality
    };
  } catch (error) {
    return handleError("DALL-E", error);
  }
}

// ==================== 3. ØªÙ„Ø®ÙŠØµ Ø§Ù„Ù†ØµÙˆØµ ====================
async function summarizeText(text, options = {}) {
  if (!text) return { status: false, message: "âš ï¸ ÙŠØ±Ø¬Ù‰ Ø¥Ø¯Ø®Ø§Ù„ Ù†Øµ Ù„Ù„ØªÙ„Ø®ÙŠØµ!" };
  
  const apiKey = process.env.HUGGINGFACE_API_KEY;
  const useOpenAI = options.useOpenAI || !apiKey;

  if (useOpenAI) {
    const prompt = `Ù„Ø®Øµ Ø§Ù„Ù†Øµ Ø§Ù„ØªØ§Ù„ÙŠ Ø¨Ø§Ù„Ù„ØºØ© Ø§Ù„Ø¹Ø±Ø¨ÙŠØ© Ø¨Ø§Ø®ØªØµØ§Ø±:\n\n${text}`;
    return await chatWithGPT(prompt, { 
      model: "gpt-3.5-turbo-16k",
      max_tokens: 500 
    });
  }

  try {
    const { data } = await axios.post(
      `${aiServices.huggingface.base}${aiServices.huggingface.endpoints.summarization}`,
      {
        inputs: text,
        parameters: {
          max_length: 130,
          min_length: 30,
          do_sample: false
        }
      },
      {
        headers: {
          ...commonHeaders,
          'Authorization': `Bearer ${apiKey}`
        }
      }
    );

    return {
      status: true,
      service: "Hugging Face Summarization",
      original_length: text.length,
      summary: data[0].summary_text,
      model: "facebook/bart-large-cnn"
    };
  } catch (error) {
    return handleError("Hugging Face", error);
  }
}

// ==================== 4. ØªØ±Ø¬Ù…Ø© Ø§Ù„Ù†ØµÙˆØµ ====================
async function translateText(text, targetLang = "en", sourceLang = "ar") {
  if (!text) return { status: false, message: "âš ï¸ ÙŠØ±Ø¬Ù‰ Ø¥Ø¯Ø®Ø§Ù„ Ù†Øµ Ù„Ù„ØªØ±Ø¬Ù…Ø©!" };
  
  const apiKey = process.env.HUGGINGFACE_API_KEY;
  if (!apiKey) {
    // Ø§Ø³ØªØ®Ø¯Ø§Ù… ChatGPT ÙƒØ¨Ø¯ÙŠÙ„
    const prompt = `ØªØ±Ø¬Ù… Ø§Ù„Ù†Øµ Ø§Ù„ØªØ§Ù„ÙŠ Ù…Ù† ${sourceLang} Ø¥Ù„Ù‰ ${targetLang}:\n\n${text}`;
    const result = await chatWithGPT(prompt, { max_tokens: 1000 });
    if (result.status) {
      return {
        ...result,
        service: "OpenAI Translation",
        original_text: text,
        source_language: sourceLang,
        target_language: targetLang
      };
    }
    return result;
  }

  const modelPath = sourceLang === "ar" && targetLang === "en" 
    ? aiServices.huggingface.endpoints.translation
    : `/Helsinki-NLP/opus-mt-${sourceLang}-${targetLang}`;

  try {
    const { data } = await axios.post(
      `${aiServices.huggingface.base}${modelPath}`,
      {
        inputs: text
      },
      {
        headers: {
          ...commonHeaders,
          'Authorization': `Bearer ${apiKey}`
        }
      }
    );

    return {
      status: true,
      service: "Hugging Face Translation",
      original_text: text,
      translated_text: data[0].translation_text,
      source_language: sourceLang,
      target_language: targetLang,
      model: modelPath.split('/').pop()
    };
  } catch (error) {
    return handleError("Translation Service", error);
  }
}

// ==================== 5. ØªØ­Ù„ÙŠÙ„ Ø§Ù„Ù…Ø´Ø§Ø¹Ø± ====================
async function analyzeSentiment(text) {
  if (!text) return { status: false, message: "âš ï¸ ÙŠØ±Ø¬Ù‰ Ø¥Ø¯Ø®Ø§Ù„ Ù†Øµ Ù„ØªØ­Ù„ÙŠÙ„ Ø§Ù„Ù…Ø´Ø§Ø¹Ø±!" };
  
  const apiKey = process.env.HUGGINGFACE_API_KEY;
  const useOpenAI = !apiKey;

  if (useOpenAI) {
    const prompt = `Ø­Ù„Ù„ Ø§Ù„Ù…Ø´Ø§Ø¹Ø± ÙÙŠ Ø§Ù„Ù†Øµ Ø§Ù„ØªØ§Ù„ÙŠ ÙˆØ­Ø¯Ø¯ Ø¥Ø°Ø§ ÙƒØ§Ù†Øª Ø¥ÙŠØ¬Ø§Ø¨ÙŠØ©ØŒ Ø³Ù„Ø¨ÙŠØ©ØŒ Ø£Ùˆ Ù…Ø­Ø§ÙŠØ¯Ø©:\n\n${text}\n\nØ£Ø¬Ø¨ Ø¨Ù†Ù…ÙˆØ°Ø¬ JSON: {"sentiment": "...", "confidence": ..., "explanation": "..."}`;
    const result = await chatWithGPT(prompt);
    if (result.status) {
      try {
        const analysis = JSON.parse(result.response);
        return {
          status: true,
          service: "OpenAI Sentiment Analysis",
          text: text,
          ...analysis
        };
      } catch (e) {
        return {
          status: true,
          service: "OpenAI Sentiment Analysis",
          text: text,
          sentiment: "unknown",
          analysis: result.response
        };
      }
    }
    return result;
  }

  try {
    const { data } = await axios.post(
      `${aiServices.huggingface.base}${aiServices.huggingface.endpoints.sentiment}`,
      {
        inputs: text
      },
      {
        headers: {
          ...commonHeaders,
          'Authorization': `Bearer ${apiKey}`
        }
      }
    );

    const sentiment = data[0][0].label;
    const score = data[0][0].score;

    return {
      status: true,
      service: "Hugging Face Sentiment Analysis",
      text: text,
      sentiment: sentiment === "POSITIVE" ? "positive" : "negative",
      confidence: score,
      scores: data[0]
    };
  } catch (error) {
    return handleError("Sentiment Analysis", error);
  }
}

// ==================== 6. ØªÙˆÙ„ÙŠØ¯ Ù†ØµÙˆØµ Ø¥Ø¨Ø¯Ø§Ø¹ÙŠØ© ====================
async function generateCreativeText(prompt, options = {}) {
  if (!prompt) return { status: false, message: "âš ï¸ ÙŠØ±Ø¬Ù‰ ÙƒØªØ§Ø¨Ø© Ø³Ø¤Ø§Ù„ Ø£Ùˆ ÙÙƒØ±Ø©!" };
  
  const {
    type = "story",
    length = "medium",
    style = "formal"
  } = options;

  const instructions = {
    story: "Ø§ÙƒØªØ¨ Ù‚ØµØ© Ù‚ØµÙŠØ±Ø©",
    poem: "Ø§ÙƒØªØ¨ Ù‚ØµÙŠØ¯Ø©",
    article: "Ø§ÙƒØªØ¨ Ù…Ù‚Ø§Ù„Ø©",
    dialogue: "Ø§ÙƒØªØ¨ Ø­ÙˆØ§Ø±Ø§Ù‹"
  }[type] || "Ø§ÙƒØªØ¨ Ù†ØµØ§Ù‹";

  const lengthMap = {
    short: "Ù‚ØµÙŠØ± (100-200 ÙƒÙ„Ù…Ø©)",
    medium: "Ù…ØªÙˆØ³Ø· (200-500 ÙƒÙ„Ù…Ø©)",
    long: "Ø·ÙˆÙŠÙ„ (500-1000 ÙƒÙ„Ù…Ø©)"
  };

  const fullPrompt = `${instructions} Ø­ÙˆÙ„: "${prompt}"\n\nØ§Ù„Ù†Ù…Ø·: ${style}\nØ§Ù„Ø·ÙˆÙ„: ${lengthMap[length] || length}`;

  return await chatWithGPT(fullPrompt, {
    model: "gpt-4",
    temperature: 0.8,
    max_tokens: length === "long" ? 2000 : length === "medium" ? 1000 : 500
  });
}

// ==================== 7. Ù…Ù‚Ø§Ø±Ù†Ø© Ø¨ÙŠÙ† Ù†Ù…ÙˆØ°Ø¬ÙŠÙ† AI ====================
async function compareAIResponses(query, models = ["gpt-3.5-turbo", "gpt-4"]) {
  if (!query) return { status: false, message: "âš ï¸ ÙŠØ±Ø¬Ù‰ ÙƒØªØ§Ø¨Ø© Ø³Ø¤Ø§Ù„ Ù„Ù„Ù…Ù‚Ø§Ø±Ù†Ø©!" };
  
  const apiKey = process.env.OPENAI_API_KEY;
  if (!apiKey) {
    return { 
      status: false, 
      message: "âŒ Ù…ÙØªØ§Ø­ OpenAI ØºÙŠØ± Ù…ÙˆØ¬ÙˆØ¯. Ø§Ø¶Ø¨Ø· OPENAI_API_KEY ÙÙŠ Ø§Ù„Ø¨ÙŠØ¦Ø©." 
    };
  }

  try {
    const promises = models.map(model => 
      chatWithGPT(query, { model })
    );

    const results = await Promise.all(promises);
    
    return {
      status: true,
      service: "OpenAI Model Comparison",
      query: query,
      comparisons: results.map((result, index) => ({
        model: models[index],
        response: result.status ? result.response : result.message,
        status: result.status ? "success" : "failed",
        tokens: result.status ? result.usage?.total_tokens : null
      })),
      fastest_model: results[0]?.status ? models[0] : null,
      most_detailed: results.reduce((best, current, idx) => {
        if (!current.status) return best;
        const currentLength = current.response?.length || 0;
        const bestLength = best.response?.length || 0;
        return currentLength > bestLength ? { model: models[idx], response: current.response } : best;
      }, { model: null, response: null })
    };
  } catch (error) {
    return handleError("AI Comparison", error);
  }
}

// ==================== Ø§Ù„Ø±ÙˆØ§ØªØ± Ø§Ù„Ø±Ø¦ÙŠØ³ÙŠ ====================
router.get('/', async (req, res) => {
  const { service, query } = req.query;

  if (!service) {
    return res.json({
      status: true,
      creator: "AI Services API",
      message: "ğŸ“Œ Ø§Ø®ØªØ± Ø®Ø¯Ù…Ø© Ù…Ù† Ø§Ù„Ù‚Ø§Ø¦Ù…Ø©:",
      available_services: [
        { name: "chat", endpoint: "/?service=chat&query=Ù†ØµÙƒ" },
        { name: "image", endpoint: "/?service=image&query=ÙˆØµÙ Ø§Ù„ØµÙˆØ±Ø©" },
        { name: "summarize", endpoint: "/?service=summarize&query=Ø§Ù„Ù†Øµ" },
        { name: "translate", endpoint: "/?service=translate&text=Ø§Ù„Ù†Øµ&target=en" },
        { name: "sentiment", endpoint: "/?service=sentiment&text=Ø§Ù„Ù†Øµ" },
        { name: "creative", endpoint: "/?service=creative&query=Ø§Ù„ÙÙƒØ±Ø©&type=story" },
        { name: "compare", endpoint: "/?service=compare&query=Ø§Ù„Ø³Ø¤Ø§Ù„&models=gpt-3.5,gpt-4" }
      ],
      examples: {
        chat: "/api/ai?service=chat&query=Ù…Ø±Ø­Ø¨Ø§ØŒ ÙƒÙŠÙ Ø­Ø§Ù„ÙƒØŸ",
        image: "/api/ai?service=image&query=Ù…Ù†Ø¸Ø± Ø·Ø¨ÙŠØ¹ÙŠ Ù„ØºØ±ÙˆØ¨ Ø§Ù„Ø´Ù…Ø³",
        summarize: "/api/ai?service=summarize&query=Ù†Øµ Ø·ÙˆÙŠÙ„ Ù„Ù„ØªÙ„Ø®ÙŠØµ..."
      }
    });
  }

  let result;
  switch (service.toLowerCase()) {
    case 'chat':
      result = await chatWithGPT(query, req.query);
      break;
    
    case 'image':
      result = await generateImage(query, req.query);
      break;
    
    case 'summarize':
      result = await summarizeText(query, req.query);
      break;
    
    case 'translate':
      result = await translateText(
        query || req.query.text, 
        req.query.target || 'en',
        req.query.source || 'ar'
      );
      break;
    
    case 'sentiment':
      result = await analyzeSentiment(query || req.query.text);
      break;
    
    case 'creative':
      result = await generateCreativeText(query, req.query);
      break;
    
    case 'compare':
      const models = req.query.models ? req.query.models.split(',') : ["gpt-3.5-turbo", "gpt-4"];
      result = await compareAIResponses(query, models);
      break;
    
    default:
      result = { status: false, message: "âŒ Ø®Ø¯Ù…Ø© ØºÙŠØ± Ù…Ø¹Ø±ÙˆÙØ©!" };
  }

  return res.status(result.status ? 200 : 500).json(result);
});

// ==================== Ù†Ù‚Ø§Ø· Ù†Ù‡Ø§ÙŠØ© Ù…Ù†ÙØµÙ„Ø© ====================
router.get('/chat', async (req, res) => {
  const { query, model, temperature } = req.query;
  const result = await chatWithGPT(query, { model, temperature });
  res.status(result.status ? 200 : 500).json(result);
});

router.get('/image', async (req, res) => {
  const { query, size, n } = req.query;
  const result = await generateImage(query, { size, n });
  res.status(result.status ? 200 : 500).json(result);
});

router.get('/summarize', async (req, res) => {
  const { text, useOpenAI } = req.query;
  const result = await summarizeText(text, { useOpenAI: useOpenAI === 'true' });
  res.status(result.status ? 200 : 500).json(result);
});

router.get('/translate', async (req, res) => {
  const { text, target, source } = req.query;
  const result = await translateText(text, target, source);
  res.status(result.status ? 200 : 500).json(result);
});

router.get('/sentiment', async (req, res) => {
  const { text } = req.query;
  const result = await analyzeSentiment(text);
  res.status(result.status ? 200 : 500).json(result);
});

router.get('/creative', async (req, res) => {
  const { prompt, type, length } = req.query;
  const result = await generateCreativeText(prompt, { type, length });
  res.status(result.status ? 200 : 500).json(result);
});

router.get('/compare', async (req, res) => {
  const { query, models } = req.query;
  const modelList = models ? models.split(',') : ["gpt-3.5-turbo", "gpt-4"];
  const result = await compareAIResponses(query, modelList);
  res.status(result.status ? 200 : 500).json(result);
});

// ==================== Ù†Ù‚Ø·Ø© Ù†Ù‡Ø§ÙŠØ© Ù„Ø¬Ù…ÙŠØ¹ Ø§Ù„Ø®Ø¯Ù…Ø§Øª ====================
router.get('/all-services', (req, res) => {
  res.json({
    status: true,
    services: [
      {
        name: "Chat with AI",
        description: "Ù…Ø­Ø§Ø¯Ø«Ø© Ù…Ø¹ Ø§Ù„Ø°ÙƒØ§Ø¡ Ø§Ù„Ø§ØµØ·Ù†Ø§Ø¹ÙŠ",
        endpoint: "/api/ai/chat?query=Ù†ØµÙƒ",
        parameters: ["query", "model", "temperature"]
      },
      {
        name: "Generate Images",
        description: "ØªÙˆÙ„ÙŠØ¯ ØµÙˆØ± Ø¨Ø§Ø³ØªØ®Ø¯Ø§Ù… Ø§Ù„Ø°ÙƒØ§Ø¡ Ø§Ù„Ø§ØµØ·Ù†Ø§Ø¹ÙŠ",
        endpoint: "/api/ai/image?query=ÙˆØµÙ Ø§Ù„ØµÙˆØ±Ø©",
        parameters: ["query", "size", "n"]
      },
      {
        name: "Text Summarization",
        description: "ØªÙ„Ø®ÙŠØµ Ø§Ù„Ù†ØµÙˆØµ Ø§Ù„Ø·ÙˆÙŠÙ„Ø©",
        endpoint: "/api/ai/summarize?text=Ø§Ù„Ù†Øµ",
        parameters: ["text", "useOpenAI"]
      },
      {
        name: "Translation",
        description: "ØªØ±Ø¬Ù…Ø© Ø§Ù„Ù†ØµÙˆØµ Ø¨ÙŠÙ† Ø§Ù„Ù„ØºØ§Øª",
        endpoint: "/api/ai/translate?text=Ù…Ø±Ø­Ø¨Ø§&target=en&source=ar",
        parameters: ["text", "target", "source"]
      },
      {
        name: "Sentiment Analysis",
        description: "ØªØ­Ù„ÙŠÙ„ Ø§Ù„Ù…Ø´Ø§Ø¹Ø± ÙÙŠ Ø§Ù„Ù†ØµÙˆØµ",
        endpoint: "/api/ai/sentiment?text=Ø£Ù†Ø§ Ø³Ø¹ÙŠØ¯ Ø¬Ø¯Ø§",
        parameters: ["text"]
      },
      {
        name: "Creative Writing",
        description: "ØªÙˆÙ„ÙŠØ¯ Ù†ØµÙˆØµ Ø¥Ø¨Ø¯Ø§Ø¹ÙŠØ© (Ù‚ØµØµØŒ Ø´Ø¹Ø±ØŒ Ù…Ù‚Ø§Ù„Ø§Øª)",
        endpoint: "/api/ai/creative?prompt=ÙÙƒØ±Ø© Ø§Ù„Ù‚ØµØ©&type=story",
        parameters: ["prompt", "type", "length"]
      },
      {
        name: "AI Model Comparison",
        description: "Ù…Ù‚Ø§Ø±Ù†Ø© Ø±Ø¯ÙˆØ¯ Ù†Ù…Ø§Ø°Ø¬ Ø§Ù„Ø°ÙƒØ§Ø¡ Ø§Ù„Ø§ØµØ·Ù†Ø§Ø¹ÙŠ Ø§Ù„Ù…Ø®ØªÙ„ÙØ©",
        endpoint: "/api/ai/compare?query=Ø³Ø¤Ø§Ù„&models=gpt-3.5,gpt-4",
        parameters: ["query", "models"]
      }
    ],
    environment_variables: [
      "OPENAI_API_KEY (Ù…Ø·Ù„ÙˆØ¨ Ù„Ø®Ø¯Ù…Ø§Øª OpenAI)",
      "HUGGINGFACE_API_KEY (Ø§Ø®ØªÙŠØ§Ø±ÙŠ Ù„Ù„Ø®Ø¯Ù…Ø§Øª Ø§Ù„Ù…Ø¬Ø§Ù†ÙŠØ©)"
    ],
    examples: [
      "Chat: /api/ai/chat?query=Ø§Ø´Ø±Ø­ Ù†Ø¸Ø±ÙŠØ© Ø§Ù„Ù†Ø³Ø¨ÙŠØ©",
      "Image: /api/ai/image?query=Ù‚Ø·Ø© ØªÙ„Ø¹Ø¨ Ø¨Ø§Ù„ÙƒØ±Ø©&size=512x512",
      "Translate: /api/ai/translate?text=Ù…Ø±Ø­Ø¨Ø§ Ø¨Ø§Ù„Ø¹Ø§Ù„Ù…&target=en"
    ]
  });
});

export default router;
